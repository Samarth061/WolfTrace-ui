# WolfTrace Data Mode Guide

## Overview

WolfTrace frontend supports two data modes:
1. **Mock Data Mode** - Uses hardcoded data from `lib/mock-data.ts`
2. **Backend Mode** - Connects to Shadow Bureau FastAPI backend

Switch between modes using the `NEXT_PUBLIC_USE_BACKEND` environment variable.

---

## Current Mode Status

**Check current mode:**
```bash
cat /home/harsha/Documents/temp/hackathon/WolfTrace-ui/.env.local
```

**Currently configured:**
```bash
NEXT_PUBLIC_USE_BACKEND=false  # Mock Data Mode
```

---

## Mode Comparison

| Feature | Mock Data Mode | Backend Mode |
|---------|---------------|--------------|
| **Data Source** | `lib/mock-data.ts` | http://localhost:8000 |
| **Data Persistence** | Always available | Requires backend running |
| **Real-time Updates** | No | Yes (via WebSocket) |
| **Case Count** | 11 fixed cases | Dynamic (from backend) |
| **Evidence Processing** | Pre-defined | AI-powered (claims, urgency, etc.) |
| **Best For** | Development, demos, testing UI | Integration testing, production |

---

## How to Switch Modes

### Switch to Mock Data Mode

**Use when:**
- Demonstrating specific scenarios (e.g., fire misinformation)
- Backend is not running
- Testing UI components without API dependency
- Showcasing mock data scenarios like case-011

**Steps:**
1. Edit `.env.local`:
   ```bash
   NEXT_PUBLIC_USE_BACKEND=false
   ```

2. Restart dev server:
   ```bash
   # Ctrl+C to stop, then:
   npm run dev
   ```

3. Verify in browser console:
   ```javascript
   // Should NOT see WebSocket connection messages
   // Cases will load from mock-data.ts immediately
   ```

**What You'll See:**
- âœ… 11 cases including "The Phantom Fire" (case-011)
- âœ… Pre-defined evidence with authenticity signals
- âœ… Evidence connections showing inference patterns
- âŒ No real-time updates
- âŒ No AI processing of new tips

---

### Switch to Backend Mode

**Use when:**
- Testing backend integration
- Using AI processing features
- Testing real-time WebSocket updates
- Submitting new tips that need processing

**Steps:**
1. **Start backend server:**
   ```bash
   cd /home/harsha/Documents/temp/hackathon/wolf-trace-backend
   uv run uvicorn app.main:app --reload
   ```

2. **Verify backend is running:**
   ```bash
   curl http://localhost:8000/health
   # Expected: {"status":"ok","controller_running":true}
   ```

3. **Edit `.env.local`:**
   ```bash
   NEXT_PUBLIC_USE_BACKEND=true
   NEXT_PUBLIC_API_URL=http://localhost:8000
   ```

4. **Restart frontend:**
   ```bash
   # Ctrl+C to stop, then:
   npm run dev
   ```

5. **Verify in browser console:**
   ```javascript
   // Should see:
   // âœ… WebSocket connected: ws://localhost:8000/ws/caseboard
   // ðŸ“¨ WebSocket message: {type: "snapshots", payload: [...]}
   // âœ… Backend data loaded: {cases: N, evidence: M, ...}
   ```

**What You'll See:**
- âœ… Cases from backend (may differ from mock data)
- âœ… Real-time updates when new tips arrive
- âœ… AI-processed evidence (claims, urgency, semantic_role)
- âœ… Evidence persists in backend (until restart)
- âŒ Mock scenarios like case-011 won't appear (unless added to backend)

---

## Data Structure Differences

### Mock Data (lib/mock-data.ts)

```typescript
// Manually crafted scenarios
export const mockCases: Case[] = [
  {
    id: 'case-011',
    codename: 'The Phantom Fire',
    status: 'Debunked',
    evidenceCount: 3,
    // ... full details
  }
]

export const mockEvidence: Evidence[] = [
  {
    id: 'ev-028',
    authenticity: 'suspicious',
    authenticitySignals: [
      'Account age: 2 days (suspicious for emergency report)',
      'No corroborating witnesses'
    ]
    // ... full details
  }
]
```

**Characteristics:**
- Fixed IDs (case-001, ev-028, etc.)
- Hand-crafted authenticity signals
- Pre-defined connections
- 11 cases covering various scenarios

---

### Backend Data (from API)

```typescript
// Dynamically generated by backend
{
  id: 'E-FC6CB420891C',  // UUID-style IDs
  node_type: 'report',
  data: {
    text_body: 'Officer notes from scene',
    claims: [
      {text: 'Fire detected', confidence: 0.85}
    ],
    urgency: 0.3,
    semantic_role: 'description'
  },
  created_at: '2026-02-14T15:30:00'
}
```

**Characteristics:**
- UUID-based IDs (E-xxxxxxxx)
- AI-extracted claims and entities
- Dynamically calculated urgency scores
- Semantic role classification
- Fact-checking results (if external sources available)

---

## Mock Data Scenarios

### Available Scenarios (in Mock Mode)

| Case ID | Codename | Status | Description | Evidence Count |
|---------|----------|--------|-------------|----------------|
| case-001 | The Clocktower Signal | Investigating | RF emissions near bell tower | 10 |
| case-002 | The Vanishing Mural | Confirmed | Mural appeared and vanished mysteriously | 8 |
| case-003 | The Fog Machine | Investigating | Aerosol emissions in Engineering Lab | 9 |
| case-004 | The Phantom Ledger | Debunked | Hidden ledger was student art project | 4 |
| case-005 | The Midnight Whistle | Investigating | Whistle pattern at midnight | 6 |
| case-006 | The Copper Wire Trail | Confirmed | Unauthorized wiring in tunnels | 5 |
| case-007 | The Glass Eye | All-clear | Suspicious device was old smoke detector | 3 |
| case-008 | The Echo Chamber | Investigating | Anomalous audio in Music Hall | 7 |
| case-009 | The Paper Trail | Closed | Missing docs found in wrong cabinet | 2 |
| case-010 | The Blank Frequency | Investigating | Unauthorized radio broadcast | 5 |
| **case-011** | **The Phantom Fire** | **Debunked** | **Fire misinformation campaign** | **3** |

**New:** case-011 demonstrates misinformation detection via evidence connections and inference.

---

## Fire Scenario with Backend AI Inference

**UPDATED:** Now uses automated setup script with real AI inference via Blackboard Architecture pipelines.

### Quick Setup

1. **Ensure backend is running:**
   ```bash
   cd /home/harsha/Documents/temp/hackathon/wolf-trace-backend
   uv run uvicorn app.main:app --reload

   # Verify health
   curl http://localhost:8000/health
   # Expected: {"status":"ok","controller_running":true,"knowledge_sources":7}
   ```

2. **Switch to backend mode:**
   ```bash
   cd /home/harsha/Documents/temp/hackathon/WolfTrace-ui
   echo "NEXT_PUBLIC_USE_BACKEND=true" > .env.local
   echo "NEXT_PUBLIC_API_URL=http://localhost:8000" >> .env.local
   ```

3. **IMPORTANT - Restart frontend dev server:**
   ```bash
   # Press Ctrl+C to stop the running dev server, then:
   npm run dev
   ```
   **Why:** Next.js caches `NEXT_PUBLIC_*` environment variables. The server must be restarted for changes to take effect.

4. **Run automated setup script:**
   ```bash
   chmod +x setup-fire-scenario.sh
   ./setup-fire-scenario.sh
   ```

   The script will:
   - Check backend health
   - POST 3 evidence items (student report, official report, fake image)
   - Wait for AI pipelines to process (CLUSTERING, NETWORK, FORENSICS)
   - Create cross-case edges if needed
   - Display case graph with colored output

5. **View case at http://localhost:3000**
   - **Hard refresh browser:** `Ctrl+Shift+R` (Windows/Linux) or `Cmd+Shift+R` (Mac)
   - Browser console should show:
     ```
     âœ… WebSocket connected: ws://localhost:8000/ws/caseboard
     ðŸ“¨ WebSocket message: {type: "snapshots", payload: [...]}
     âœ… Backend data loaded: {cases: 3, evidence: X, connections: Y, tips: Z}
     ```
   - Bureau Wall should display the fire case
   - Evidence Network shows automatically inferred relationships

### What You'll See

**Automatic AI Inference via Pipelines:**
- **CLUSTERING pipeline** (Priority: CRITICAL) - Creates SIMILAR_TO edges
  - Temporal matching: 30-minute time window
  - Geospatial matching: 200m radius
  - Semantic matching: keyword overlap analysis
  - Combined threshold: 0.4 (weighted: 0.3 temporal + 0.3 geo + 0.4 semantic)

- **NETWORK pipeline** (Priority: MEDIUM) - Extracts claims and fact-checks
  - AI claim extraction using Backboard/Gemini
  - Google Fact Check API integration
  - Creates EXTERNAL_SOURCE nodes from web searches
  - Creates DEBUNKED_BY edges for contradictions

- **CLASSIFIER pipeline** (Priority: LOW) - Assigns semantic roles
  - Originator: First to report information
  - Amplifier: Spreads existing information
  - Mutator: Modifies or alters information
  - Unwitting Sharer: Unknowingly spreads false info

- **FORENSICS pipeline** (Priority: HIGH) - Analyzes media
  - ELA (Error Level Analysis) for image manipulation
  - pHash signature for reverse image search
  - EXIF metadata extraction
  - TwelveLabs video analysis

**Expected Results:**
- âœ… Dynamic case creation (CASE-Cold-Code-1335, CASE-Iron-Asset-6425)
- âœ… Automatic SIMILAR_TO edges between evidence (from CLUSTERING)
- âœ… EXTERNAL_SOURCE nodes (from web searches)
- âœ… FACT_CHECK nodes (if matches found)
- âœ… Real-time WebSocket updates
- âœ… Confidence scores for relationships
- âœ… AI-extracted claims with semantic roles

### Manual Setup (Advanced)

If you prefer to run curl commands manually instead of using the script, see the example commands in [setup-fire-scenario.sh](setup-fire-scenario.sh).

---

## Troubleshooting

### "I don't see cases in the frontend" (Backend Mode)

**Most Common Issue:** Frontend dev server needs restart after `.env.local` change.

**Quick Fix:**
1. **Restart frontend dev server:**
   ```bash
   # In the terminal running the dev server:
   # Press Ctrl+C to stop
   npm run dev
   ```

2. **Hard refresh browser:** `Ctrl+Shift+R` (clears cached JavaScript)

3. **Check browser console** (F12 or Ctrl+Shift+I):
   - âœ… Should see: `WebSocket connected: ws://localhost:8000/ws/caseboard`
   - âœ… Should see: `Backend data loaded: {cases: N, ...}`
   - âŒ If you see mock data or no WebSocket messages â†’ server needs restart

**Detailed Diagnosis:**

1. **Verify backend has cases:**
   ```bash
   curl http://localhost:8000/api/cases
   # Should show CASE-Cold-Code-1335, CASE-Iron-Asset-6425, etc.
   ```
   - If empty: Backend was restarted (in-memory storage cleared) â†’ re-run `./setup-fire-scenario.sh`
   - If error: Backend not running â†’ start backend first

2. **Check environment variable:**
   ```bash
   cat .env.local
   # Should show: NEXT_PUBLIC_USE_BACKEND=true
   ```
   - If false: Change to true and restart dev server
   - If missing: Create the file with the correct settings

3. **Check WebSocket in browser:**
   - Open DevTools â†’ Network tab â†’ WS (WebSocket) filter
   - Should see connection to `ws://localhost:8000/ws/caseboard`
   - Status should be "101 Switching Protocols" (successful)
   - If failed: Backend WebSocket endpoint not responding

4. **Check frontend console for errors:**
   - Look for red error messages
   - Common issues:
     - CORS errors â†’ backend CORS config issue
     - Network errors â†’ backend not reachable
     - Parsing errors â†’ backend response format changed

**Why This Happens:**
- Next.js caches `NEXT_PUBLIC_*` environment variables at build time
- Changing `.env.local` doesn't affect the running server
- The server must be fully stopped and restarted for env changes to load

---

### "I don't see case-011 in the UI" (Mock Mode)

**Check:**
1. Are you in Mock Data Mode?
   ```bash
   cat .env.local | grep NEXT_PUBLIC_USE_BACKEND
   # Should show: false
   ```

2. Did you restart the dev server after changing `.env.local`?
   ```bash
   # Ctrl+C, then npm run dev
   ```

3. Check browser console for errors

---

### "I see weird IDs like E-FC6CB420891C"

**Cause:** You're in Backend Mode, seeing backend-generated evidence

**Solution:**
- Switch to Mock Data Mode (see above)
- OR add the fire scenario to backend (see "Adding Mock Scenarios to Backend")

---

### "Pipelines don't create edges automatically"

**Issue:** Evidence is added but CLUSTERING/NETWORK pipelines don't create relationships.

**Check:**

1. **Verify Blackboard Controller is running:**
   ```bash
   curl http://localhost:8000/health
   # Expected: {"controller_running": true, "knowledge_sources": 7}
   ```

2. **Check evidence timestamps are within 30 minutes:**
   - CLUSTERING pipeline uses 30-minute temporal window
   - Example: Student at 22:15, Official at 22:22 = 7 min âœ“
   - If timestamps are too far apart, reduce the gap

3. **Use same location coordinates:**
   - CLUSTERING has 200m geo radius threshold
   - All evidence should use identical lat/lng values
   - Example: `lat: 40.7489, lng: -73.9681`

4. **Add overlapping keywords:**
   - Semantic score requires keyword overlap
   - Example: All mention "Science Building", "fire", "East Wing"
   - Contributes 0.4 to total score (threshold: 0.4 overall)

5. **Check backend logs for pipeline activity:**
   ```
   INFO: Blackboard evaluating: node:report for RPT-XXXXXX
   INFO: Running knowledge source: clustering (priority: CRITICAL)
   INFO: Created edge: RPT-XXX â†’ RPT-YYY (similar_to, conf=0.75)
   ```

**Scoring Details:**
- Temporal: 0.3 weight (decays over 30 min)
- Geo: 0.3 weight (within 200m)
- Semantic: 0.4 weight (keyword overlap)
- **Combined threshold: 0.4** to create SIMILAR_TO edge

---

### "WebSocket keeps failing"

**Cause:** In Backend Mode but backend server not running

**Solutions:**
1. **Start backend:**
   ```bash
   cd /home/harsha/Documents/temp/hackathon/wolf-trace-backend
   uv run uvicorn app.main:app --reload
   ```

2. **OR switch to Mock Data Mode** (no WebSocket needed)

3. **Check WebSocket endpoint:**
   ```bash
   curl -i http://localhost:8000/health
   # Should return 200 OK
   ```

4. **Verify backend started before frontend:**
   - Backend must be running when frontend connects
   - If frontend starts first, WebSocket connection fails
   - Solution: Restart frontend after backend is up

---

### "Changes to mock-data.ts not appearing"

**Check:**
1. Are you in Mock Data Mode? (`NEXT_PUBLIC_USE_BACKEND=false`)
2. Did you save the file?
3. Did the dev server recompile? (Check terminal for "âœ“ Compiled")
4. Hard refresh browser: `Ctrl+Shift+R` (Windows/Linux) or `Cmd+Shift+R` (Mac)

---

## Quick Reference Commands

```bash
# Check current mode
cat .env.local

# Switch to Mock Data
echo "NEXT_PUBLIC_USE_BACKEND=false" > .env.local
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" >> .env.local

# Switch to Backend
echo "NEXT_PUBLIC_USE_BACKEND=true" > .env.local
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" >> .env.local

# Restart frontend
# Press Ctrl+C in the dev server terminal, then:
npm run dev

# Start backend (for Backend Mode)
cd /home/harsha/Documents/temp/hackathon/wolf-trace-backend
uv run uvicorn app.main:app --reload

# Check backend health
curl http://localhost:8000/health
```

---

## Summary

- **Mock Mode:** Fast, reliable, shows curated scenarios like case-011
- **Backend Mode:** Dynamic, AI-powered, real-time updates
- **Switch via:** `.env.local` â†’ `NEXT_PUBLIC_USE_BACKEND=true/false`
- **Always restart** dev server after changing `.env.local`
- **For demos:** Use Mock Mode to show specific scenarios
- **For testing:** Use Backend Mode to test integration
